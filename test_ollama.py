# test_ollama.py - Complete Ollama test for your blog project
import requests
import json
import time

def test_ollama_connection():
    """Test Ollama API connection and model availability"""
    print("ğŸ¦™ Testing Ollama Connection...")
    print("=" * 50)
    
    # Test 1: Check if Ollama is running
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            print("âœ… Ollama is running on localhost:11434")
            
            models = response.json().get('models', [])
            print(f"ğŸ“¦ Available models: {len(models)}")
            
            # List all models
            for model in models:
                print(f"   - {model.get('name', 'Unknown')}")
            
            # Check if llama3.2 is available
            llama_models = [m for m in models if 'llama3.2' in m.get('name', '')]
            if llama_models:
                print("âœ… llama3.2 model is available")
                model_name = llama_models[0]['name']
                print(f"   Using model: {model_name}")
                return model_name
            else:
                print("âŒ llama3.2 model not found")
                print("   Run: ollama pull llama3.2")
                return None
                
        else:
            print(f"âŒ Ollama not responding (status: {response.status_code})")
            return None
            
    except requests.exceptions.ConnectionError:
        print("âŒ Cannot connect to Ollama. Is it running?")
        print("   Try: ollama serve (if not running)")
        return None
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def test_summarization(model_name):
    """Test text summarization with real blog content"""
    print("\nğŸ§  Testing text summarization...")
    print("=" * 50)
    
    # Test with Russian game dev article (like your blog content)
    test_text = """
    Ğ ĞµĞ±ÑÑ‚Ğ°, Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚! Ğ•ÑĞ»Ğ¸ Ğ·Ğ°Ğ³Ğ»ÑĞ½ÑƒÑ‚ÑŒ Ğ½Ğ° ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¸Ğ»Ğ¸ ĞºĞ°Ğ½Ğ°Ğ»Ñ‹ Ğ¿Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºÑƒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ² Ğ³ĞµĞ¹Ğ¼Ğ´ĞµĞ²Ğµ, 
    Ñ‚Ğ¾ ĞºĞ°Ğº Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ² Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ½Ğ° Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ³ĞµĞ¹Ğ¼-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€Ğ° Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ 
    Ğ² ÑĞµĞ±Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¸ ÑƒĞ¼ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ³Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸, ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ÑŒ 
    Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ§Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½ĞµĞµ Ğ´Ğ»Ñ Ğ³ĞµĞ¹Ğ¼-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€Ğ° XXI Ğ²ĞµĞºĞ°, 
    Ñ‡ĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸? 
    
    Ğ¡ÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ñ‚Ñ€Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº: Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ¸.
    
    CPI (ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°) - ÑÑ‚Ğ¾ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ñ€ĞµĞºĞ»Ğ°Ğ¼Ñƒ, Ğ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ñ… 
    Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. Conversion Rate Ğ¸Ğ·Ğ¼ĞµÑ€ÑĞµÑ‚ Ğ´Ğ¾Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, ÑĞ¾Ğ²ĞµÑ€ÑˆĞ¸Ğ²ÑˆĞ¸Ñ… Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ. 
    Retention Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ÑÑ‚ÑÑ Ğº Ğ¸Ğ³Ñ€Ğµ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ğµ 
    Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚ĞºĞ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸.
    """
    
    prompt = f"Summarize this Russian text about game development metrics in 2-3 sentences in English: {test_text.strip()}"
    
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.3,
            "max_tokens": 150
        }
    }
    
    try:
        print("â³ Generating summary (this may take 10-30 seconds)...")
        start_time = time.time()
        
        response = requests.post(
            "http://localhost:11434/api/generate", 
            json=payload,
            timeout=60
        )
        
        end_time = time.time()
        processing_time = round((end_time - start_time) * 1000)  # Convert to milliseconds
        
        if response.status_code == 200:
            data = response.json()
            summary = data.get('response', '').strip()
            
            print("âœ… Summary generated successfully!")
            print(f"â±ï¸  Processing time: {processing_time}ms")
            print(f"ğŸ“ Summary: {summary}")
            
            # Test quality
            if len(summary) > 20:
                print("âœ… Summary quality: Good")
                return True
            else:
                print("âš ï¸  Summary seems short")
                return True
                
        else:
            print(f"âŒ API call failed (status: {response.status_code})")
            print(f"Response: {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ Request timed out. Ollama might be slow or overloaded.")
        return False
    except Exception as e:
        print(f"âŒ Error during summarization: {e}")
        return False

def test_django_blog_content():
    """Test with typical Django blog content"""
    print("\nğŸ“ Testing with Django blog content...")
    print("=" * 50)
    
    blog_content = """
    <h2>Understanding Django Models and Database Integration</h2>
    <p>Django's Object-Relational Mapping (ORM) is one of its most powerful features, 
    allowing developers to interact with databases using Python code instead of raw SQL queries. 
    The Django ORM provides a high-level abstraction layer that makes database operations 
    intuitive and secure.</p>
    
    <p>Models in Django are Python classes that represent database tables. Each model class 
    corresponds to a single database table, and each attribute of the model represents a 
    database field. Django automatically generates SQL to create the database schema based 
    on your model definitions.</p>
    
    <p>Key benefits include automatic SQL generation, database-agnostic code, built-in 
    validation, and powerful query capabilities. Django supports multiple database backends 
    including PostgreSQL, MySQL, SQLite, and Oracle.</p>
    """
    
    # Clean HTML tags for summarization
    import re
    clean_content = re.sub(r'<[^>]+>', '', blog_content)
    clean_content = re.sub(r'\s+', ' ', clean_content).strip()
    
    prompt = f"Summarize this Django tutorial in exactly 2 sentences: {clean_content}"
    
    payload = {
        "model": "llama3.2",  # Direct model name
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.3,
            "max_tokens": 100
        }
    }
    
    try:
        print("â³ Processing Django content...")
        start_time = time.time()
        
        response = requests.post(
            "http://localhost:11434/api/generate", 
            json=payload,
            timeout=60
        )
        
        processing_time = round((time.time() - start_time) * 1000)
        
        if response.status_code == 200:
            data = response.json()
            summary = data.get('response', '').strip()
            
            print("âœ… Django content summary generated!")
            print(f"â±ï¸  Processing time: {processing_time}ms")
            print(f"ğŸ“ Summary: {summary}")
            print(f"ğŸ“Š Original length: {len(clean_content)} chars")
            print(f"ğŸ“Š Summary length: {len(summary)} chars")
            print(f"ğŸ“Š Compression ratio: {round(len(summary)/len(clean_content)*100, 1)}%")
            
            return True
        else:
            print(f"âŒ Failed to process Django content")
            return False
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸš€ Starting Ollama Tests for Yappuccino Blog")
    print("=" * 60)
    
    # Test 1: Connection and model availability
    model_name = test_ollama_connection()
    if not model_name:
        print("\nâŒ Cannot proceed without working Ollama setup")
        return
    
    # Test 2: Summarization with multilingual content
    success1 = test_summarization(model_name)
    
    # Test 3: Django blog content processing
    success2 = test_django_blog_content()
    
    # Results
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST RESULTS")
    print("=" * 60)
    
    if success1 and success2:
        print("âœ… All tests passed! Ollama is ready for your blog project.")
        print("ğŸ”„ Next step: Set up n8n workflow")
        print("ğŸ“Š Expected performance:")
        print("   - Processing time: 5-30 seconds per article")
        print("   - Model: llama3.2 (good for summarization)")
        print("   - Multilingual support: âœ…")
    else:
        print("âš ï¸  Some tests failed. Check Ollama setup.")
        print("ğŸ’¡ Try: ollama pull llama3.2")

if __name__ == "__main__":
    main()